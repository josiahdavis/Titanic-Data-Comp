m.logit <- glm(Survived~Pclass+Sex+Age+SibSp+Fare+family.no, family = binomial(logit), data = train.1)
models$logit[[i]] <- m.logit
p.logit <- predict(m.logit, type = "response", newdata = train.2)
r <- confusionMatrix(round(p.logit, 0), train.2$Survived)
results[i,] <- c("Logit", r$overall[1], r$byClass[1], r$byClass[2])
rm(r, m.logit)
#################
# Random Forest
##################
m.forest <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, data = train)
models$forest[[i]] <- m.forest
p.forest <- predict(m.forest, newdata = train)
r <- confusionMatrix(p.forest, train$Survived)
results[iterations+i,] <- c("Random Forest", r$overall[1], r$byClass[1], r$byClass[2])
rm(r, m.forest)
##################
# Boosted Trees
##################
m.boost <-ada(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, data=train.1, verbose=TRUE,na.action=na.rpart)
models$boost[[i]] <- m.boost
p.boost <-predict(m.boost, newdata=train.2, type="vector")
r <- confusionMatrix(p.boost, train.2$Survived)
results[iterations*2+i,] <- c("Boosted Trees", r$overall[1], r$byClass[1], r$byClass[2])
rm(r, m.boost)
#   ##################
#   # Neural Networks
#   ##################
#   m.nn <- neuralnet(formula, hidden = 6, data = train.1.n, threshold = 0.05)
#   p.nn <-ifelse(compute(m.nn,train.2.n[,2:8])$net.result>=0.5, 1, 0)
#   a.nn <- sum(p.nn==train.2.n[,1])/length(p.nn)
#   a.nn
#   confusionMatrix(p.nn, train.2.n[,1])
##################
# Naive Bayes
##################
m.nb <- naiveBayes(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Fare + Embarked + family.no, data = train.1)
models$nb[[i]] <- m.nb
p.nb<-predict(m.nb,newdata=train.2)
r <- confusionMatrix(p.nb, train.2$Survived)
results[iterations*3+i,] <- c("Naive Bayes", r$overall[1], r$byClass[1], r$byClass[2])
rm(r, m.nb)
##################
# Ensemble Model
##################
pred <- data.frame(Survival=train.2$Survived,
logit=round(p.logit, 0),
bt=p.boost,
rf=p.forest,
nb=p.nb)
m.ensemble <- randomForest(as.factor(Survival) ~ logit + bt + rf + nb, data = pred)
models$ensemble[[i]] <- m.ensemble
p.ensemble <- predict(m.ensemble, newdata = pred)
r <- confusionMatrix(p.ensemble, pred$Survival)
results[iterations*4+i,] <- c("Ensemble", r$overall[1], r$byClass[1], r$byClass[2])
rm(r, pred, m.ensemble, p.ensemble, p.logit, p.boost, p.forest, p.nb)
iterations = 5
results = data.frame(matrix(0, 5 * iterations, 4, dimnames =
list(NULL, c("Model", "Accuracy", "Sensitivity", "Specificity"))))
models <- vector(mode="list", length=iterations)
models <- list(logit = models,
forest = models,
boost = models,
nb = models,
ensemble = models)
idx <- createDataPartition(train[,3], times = 1, p = 0.60, list = FALSE)
train.1 <- train[idx,]; train.2 <- train[-idx,]
#train.1.n <- train.n[idx,]; train.2.n <- train.n[-idx,]
rm(idx)
m.logit <- glm(Survived~Pclass+Sex+Age+SibSp+Fare+family.no, family = binomial(logit), data = train)
models$logit[[i]] <- m.logit
p.logit <- predict(m.logit, type = "response", newdata = train)
m.forest <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, data = train)
models$forest[[i]] <- m.forest
p.forest <- predict(m.forest, newdata = train)
m.boost <-ada(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, data=train, verbose=TRUE,na.action=na.rpart)
models$boost[[i]] <- m.boost
p.boost <-predict(m.boost, newdata=train, type="vector")
pred <- data.frame(Survival=train$Survived,
logit=round(p.logit, 0),
bt=p.boost,
rf=p.forest)
?rowSum
?rowSums
rowSums(pred[c("logit", "bt", "rf")])
str(pred)
pred <- data.frame(Survival=train$Survived,
logit=round(p.logit, 0),
bt=as.numeric(p.boost),
rf=as.numeric(p.forest))
str(pred)
rowSums(pred[c("logit", "bt", "rf")])
pred$age <- rowSums(pred[c("logit", "bt", "rf")])
summary(pred)
summary(p.boost)
summary(as.numeric(p.boost))
pred <- data.frame(Survival=train$Survived,
logit=round(p.logit, 0),
bt=as.numeric(p.boost)-1,
rf=as.numeric(p.forest)-1)
pred$age <- NULL
pred$avg <- rowSums(pred[c("logit", "bt", "rf")])
summary(pred)
test$logit <- round(predict(models$logit[[1]], type = "response", newdata = test),0)
test$rf <- predict(models$forest[[1]], newdata = test)
test$bt <- predict(models$boost[[1]], newdata = test)
models$logit[[1]]
test$ensemble <- ifelse(rowSums(test[c("logit", "bt", "rf")])>1, 1, 0) # TRying a simple average
summary(test)
test$bt <- as.numeric(predict(models$boost[[1]], newdata = test)-1)
test$bt <- as.numeric(predict(models$boost[[1]], newdata = test))-1
test$rf <- as.numeric(predict(models$forest[[1]], newdata = test))-1
test$ensemble <- ifelse(rowSums(test[c("logit", "bt", "rf")])>1, 1, 0) # TRying a simple average
head(test)
head(test, 20)
head(test, 40)
head(test, 40)
test$Survived <- ifelse(rowSums(test[c("logit", "bt", "rf")])>1, 1, 0) # TRying a simple average
submission <- test[c("PassengerId", "Survived")]
write.csv(submission, "VICE.csv", row.names = FALSE)
models <- vector(mode="list", length=iterations)
models
?list
list(models, models, models)
models <- list(logit = models,
forest = models,
boost = models,
nb = models,
ensemble = models)
models
list(5)
list(1:5)
?list
models <- vector("list", iterations)
models
models <- list(logit = vector("list", iterations),
forest = vector("list", iterations),
boost = vector("list", iterations),
nb = vector("list", iterations),
ensemble = vector("list", iterations))
el <- vector("list", iterations)
summary(train$Cabin)
summary(combined$Cabin)
str(train)
rm(list = ls()); gc()
set.seed(98143)
library(caret)
library(rpart)
library(plyr)
library(randomForest)
library(neuralnet)
library(ada)
library(missForest)
library(e1071)
# TO-DO:
# Add spouse variable
setwd("C:/Users/josdavis/Documents/GitHub/Titanic-Data-Comp")
test <- read.csv("test.csv", header = TRUE)
train <- read.csv("train.csv", header = TRUE)
str(test)
summary(train$Cabin)
summary(grepl(" ",train$Cabin))
summary(grepl("",train$Cabin))
?is.na
m.forest <- randomForest(Survived ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, method = "class", data = train)
rm(list = ls()); gc()
set.seed(98143)
library(caret)
library(rpart)
library(plyr)
library(randomForest)
library(neuralnet)
library(ada)
library(e1071)
library(missForest)
# TO-DO:
# Add spouse variable
setwd("C:/Users/josdavis/Documents/GitHub/Titanic-Data-Comp")
test <- read.csv("test.csv", header = TRUE)
train <- read.csv("train.csv", header = TRUE)
##################
# Create Variables
##################
# Want to determine the number of family members
# Combine data sets
test$dat <- "test"
train$dat <- "train"
combined <- rbind(train[,-2], test)
# Get last name
combined$last.name <- strsplit(as.character(combined$Name), ",")
combined$last.name <- as.factor(unlist(combined$last.name)[seq(1, 2618, 2)]) #take every other element
# Count the number of names by last name
combined <- ddply(combined, c("last.name"), function(x)cbind(x, family.no = length(unique(x$Name)) - 1))
# Get Titles (for age imputation mainly)
getTitle <- function(data) {
title.dot.start <- regexpr("\\,[A-Z ]{1,20}\\.", data$Name, TRUE)
title.comma.end <- title.dot.start + attr(title.dot.start, "match.length")-1
data$Title <- substr(data$Name, title.dot.start+2, title.comma.end-1)
return (data$Title)
}
combined$Title <- as.factor(getTitle(combined))
rm(getTitle)
# Impute missing values (does not change order)
combined.i <- missForest(combined[c("Pclass", "Sex", "Age",
"SibSp", "Fare", "Embarked", "family.no", "Title")], verbose = FALSE)$ximp
combined <- cbind(combined.i, combined[c("Name", "PassengerId", "dat")])
# Split the data back to original training and testing sets
test <- combined[combined$dat == "test",]
train <- merge(combined[combined$dat == "train",], train[,c("Survived", "Name")],
by = "Name", all.x = TRUE, all.y = TRUE)
# Create a numeric version as well
# train.n <- train[c("Survived", "Pclass", "Sex", "Age",
#                             "SibSp", "Fare", "Embarked", "family.no")]
# train.n$Sex <- ifelse(train$Sex == "male", 1, 0)
# train.n$Embarked <- as.numeric(train$Embarked)
# train.n <- as.matrix(train.n)
formula <- as.formula("Survived~Pclass+Sex+Age+SibSp+Embarked+Fare+family.no")
m.forest <- randomForest(Survived ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, method = "class", data = train)
?randomForest
?cforest
library(cforest)
library(party)
?cforest
rm(list = ls()); gc()
set.seed(98143)
library(caret)
library(rpart)
library(party)
library(plyr)
library(randomForest)
library(neuralnet)
library(e1071)
library(ada)
library(missForest)
setwd("C:/Users/josdavis/Documents/GitHub/Titanic-Data-Comp")
test <- read.csv("test.csv", header = TRUE)
train <- read.csv("train.csv", header = TRUE)
##################
# Create Variables
##################
# Want to determine the number of family members
# Combine data sets
test$dat <- "test"
train$dat <- "train"
combined <- rbind(train[,-2], test)
# Get last name
combined$last.name <- strsplit(as.character(combined$Name), ",")
combined$last.name <- as.factor(unlist(combined$last.name)[seq(1, 2618, 2)]) #take every other element
# Count the number of names by last name
combined <- ddply(combined, c("last.name"), function(x)cbind(x, family.no = length(unique(x$Name)) - 1))
# Get Titles (for age imputation mainly)
getTitle <- function(data) {
title.dot.start <- regexpr("\\,[A-Z ]{1,20}\\.", data$Name, TRUE)
title.comma.end <- title.dot.start + attr(title.dot.start, "match.length")-1
data$Title <- substr(data$Name, title.dot.start+2, title.comma.end-1)
return (data$Title)
}
combined$Title <- as.factor(getTitle(combined))
rm(getTitle)
# Impute missing values (does not change order)
combined.i <- missForest(combined[c("Pclass", "Sex", "Age",
"SibSp", "Fare", "Embarked", "family.no", "Title")], verbose = FALSE)$ximp
combined <- cbind(combined.i, combined[c("Name", "PassengerId", "dat")])
# Split the data back to original training and testing sets
test <- combined[combined$dat == "test",]
train <- merge(combined[combined$dat == "train",], train[,c("Survived", "Name")],
by = "Name", all.x = TRUE, all.y = TRUE)
rm(combined, combined.i)
formula <- as.formula("Survived~Pclass+Sex+Age+SibSp+Embarked+Fare+family.no")
idx <- createDataPartition(train[,3], times = 1, p = 0.60, list = FALSE)
train.1 <- train[idx,]; train.2 <- train[-idx,]
#train.1.n <- train.n[idx,]; train.2.n <- train.n[-idx,]
rm(idx)
m.forest <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, data = train)
p.forest <- predict(m.forest, newdata = train)
r <- confusionMatrix(p.forest, train$Survived)
r
m.forest <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, data = train.1)
p.forest <- predict(m.forest, newdata = train.2)
r <- confusionMatrix(p.forest, train.2$Survived)
r
m.cforest <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, data = train.1)
p.cforest <-  predict(m.cforest, newdata = train.2)
r <- confusionMatrix(p.cforest, train.2$Survived)
r
m.cforest <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, data = train)
test$Survived <- predict(m.cforest, newdata = test) # Trying a single rf model
submission <- test[c("PassengerId", "Survived")]
hist(Pclass)
hist(train$Pclass)
hist(train$Age)
hist(train$Fare)
hist(log(train$Fare))
log(10)
log(2)
log(10^2)
head(train$Fare)
head(train$Fare, 100)
head(train, 100)
head(train, 1)
rm(list = ls()); gc()
set.seed(98143)
library(caret)
library(rpart)
library(party)
library(plyr)
library(randomForest)
library(neuralnet)
library(ada)
library(e1071)
library(missForest)
setwd("C:/Users/josdavis/Documents/GitHub/Titanic-Data-Comp")
test <- read.csv("test.csv", header = TRUE)
train <- read.csv("train.csv", header = TRUE)
test$dat <- "test"
train$dat <- "train"
combined <- rbind(train[,-2], test)
str(test)
str(train)
test$Survived <- 0 # Create the variable for now
dim(test)
dim(train)
test$Survived <- 5 # Create the variable for now
combined <- rbind(train, test)
head(combined)
head(combined[888:892,])
head(combined[889:895,])
combined$last.name <- strsplit(as.character(combined$Name), ",")
combined$last.name <- as.factor(unlist(combined$last.name)[seq(1, 2618, 2)]) #take every other element
combined <- ddply(combined, c("last.name"), function(x)cbind(x, family.no = length(unique(x$Name)) - 1))
getTitle <- function(data) {
title.dot.start <- regexpr("\\,[A-Z ]{1,20}\\.", data$Name, TRUE)
title.comma.end <- title.dot.start + attr(title.dot.start, "match.length")-1
data$Title <- substr(data$Name, title.dot.start+2, title.comma.end-1)
return (data$Title)
}
combined$Title <- as.factor(getTitle(combined))
rm(getTitle)
# Impute missing values (does not change order)
combined.i <- missForest(combined[c("Pclass", "Sex", "Age",
"SibSp", "Fare", "Embarked", "family.no", "Title")], verbose = FALSE)$ximp
?Survived
str(train)
combined.i <- missForest(combined[c("Pclass", "Sex", "Age", "Parch"
"SibSp", "Fare", "Embarked", "family.no", "Title")], verbose = FALSE)$ximp
combined.i <- missForest(combined[c("Pclass", "Sex", "Age", "Parch",
"SibSp", "Fare", "Embarked", "family.no", "Title")], verbose = FALSE)$ximp
combined <- cbind(combined.i, combined[c("Name", "PassengerId", "dat", "Survived", "Ticket", "Cabin")])
str(train)
rm(list = ls()); gc()
set.seed(98143)
library(caret)
library(rpart)
library(party)
library(plyr)
library(randomForest)
library(neuralnet)
library(ada)
library(e1071)
library(missForest)
setwd("C:/Users/josdavis/Documents/GitHub/Titanic-Data-Comp")
test <- read.csv("test.csv", header = TRUE)
train <- read.csv("train.csv", header = TRUE)
test$Survived <- 5 # Create the variable for now
test$dat <- "test"
train$dat <- "train"
combined <- rbind(train, test)
# Get last name
combined$last.name <- strsplit(as.character(combined$Name), ",")
combined$last.name <- as.factor(unlist(combined$last.name)[seq(1, 2618, 2)]) #take every other element
# Count the number of names by last name
combined <- ddply(combined, c("last.name"), function(x)cbind(x, family.no = length(unique(x$Name)) - 1))
# Get Titles (for age imputation mainly)
getTitle <- function(data) {
title.dot.start <- regexpr("\\,[A-Z ]{1,20}\\.", data$Name, TRUE)
title.comma.end <- title.dot.start + attr(title.dot.start, "match.length")-1
data$Title <- substr(data$Name, title.dot.start+2, title.comma.end-1)
return (data$Title)
}
combined$Title <- as.factor(getTitle(combined))
rm(getTitle)
combined.i <- missForest(combined[c("Pclass", "Sex", "Age", "Parch",
"SibSp", "Fare", "Embarked", "family.no", "Title")], verbose = FALSE)$ximp
combined <- cbind(combined.i, combined[c("Name", "PassengerId", "dat", "Survived", "Ticket", "Cabin")])
rm(combined.i)
?tapply
d = (TRUE, FALSE TRUE)
d = (TRUE, FALSE, TRUE)
d = c(TRUE, FALSE, TRUE)
d
any(d)
all(d)
combined <- tapply(combined, c("Ticket"), function(x)cbind(x, any.lived = any(x$Survived == 1)))
combined <- ddply(combined, c("Ticket"), function(x)cbind(x, any.lived = any(x$Survived == 1)))
str(combined)
combined <- tapply(combined, c("Ticket"), function(x)cbind(x, any.died = any(x$Survived == 0)))
combined <- ddply(combined, c("Ticket"), function(x)cbind(x, any.died = any(x$Survived == 0)))
summary(combined$any.lived)
summary(combined$any.died)
test <- combined[combined$dat == "test",]
train <- combined[combined$dat == "train",]
rm(combined, combined.i)
formula <- as.formula("Survived ~ Pclass + Sex + Age + SibSp + Embarked + Fare + family.no + any.lived")
iterations = 3
results = data.frame(matrix(0, 5 * iterations, 4, dimnames =
list(NULL, c("Model", "Accuracy", "Sensitivity", "Specificity"))))
el <- vector("list", iterations)
models <- list(logit = el,
forest = el,
boost = el,
nb = el,
ensemble = el)
idx <- createDataPartition(train[,3], times = 1, p = 0.60, list = FALSE)
train.1 <- train[idx,]; train.2 <- train[-idx,]
#train.1.n <- train.n[idx,]; train.2.n <- train.n[-idx,]
rm(idx)
rm(el)
rm(d)
m.logit <- glm(Survived~Pclass+Sex+Age+SibSp+Fare+family.no, family = binomial(logit), data = train.1)
p.logit <- predict(m.logit, type = "response", newdata = train.2)
r <- confusionMatrix(round(p.logit, 0), train$Survived)
p.logit
r <- confusionMatrix(round(p.logit, 0), train.2$Survived)
r
m.logit <- glm(Survived~Pclass+Sex+Age+SibSp+Fare+family.no+any.lived, family = binomial(logit), data = train.1)
p.logit <- predict(m.logit, type = "response", newdata = train.2)
r <- confusionMatrix(round(p.logit, 0), train.2$Survived)
r
m.forest <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no, data = train.1)
p.forest <- predict(m.forest, newdata = train.2)
r <- confusionMatrix(p.forest, train.2$Survived)
r
m.forest <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no + any.lived, data = train.1)
p.forest <- predict(m.forest, newdata = train.2)
r <- confusionMatrix(p.forest, train.2$Survived)
r
m.cforest <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no + any.lived, data = train.1)
p.cforest <-  predict(m.cforest, newdata = train.2)
r <- confusionMatrix(p.cforest, train.2$Survived)
r
p.cforest
train.1[p.cforest == 1 & train.1$Survived == 0,]
head(train.1[train.1$Survived == 0,], 10)
head(train.1[train.1$Survived == 0,], 10)
head(train.1[train.1$Survived == 0 && p.cforest == 1,], 10)
m.logit <- glm(Survived~Pclass+Sex+Age+SibSp+Fare+family.no+any.lived, family = binomial(logit), data = train.1)
models$logit[[i]] <- m.logit
p.logit <- predict(m.logit, type = "response", newdata = train.2)
r <- confusionMatrix(round(p.logit, 0), train.2$Survived)
r
m.logit
names(m.logit)
m.logit$R
m.logit$residuals
names(m.logit)
names(m.logit)
m.logit$coefficients
m.logit$effects
names(m.logit)
m.logit$deviance
m.logit$rank
m.logit$terms
m.logit$aic
train.2[train.2$Survived ==1,]
head(train.2[train.2$Survived ==1 && p.logit == 1,], 10)
dim(train.2)
head(train.2[train.2$Survived ==1 & p.logit == 1,], 10)
head(train.2[p.logit == 1,], 10)
r
r <- confusionMatrix(p.cforest, train.2$Survived)
r
m.cforest <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Fare + Embarked + family.no + any.lived, data = train)
test$Survived <- predict(m.cforest, newdata = test) # Trying a single rf model
submission <- test[c("PassengerId", "Survived")]
write.csv(submission, "VICE.csv", row.names = FALSE)
r
p.cforest <-  predict(m.cforest, newdata = train)
r <- confusionMatrix(p.cforest, train.2$Survived)
r <- confusionMatrix(p.cforest, train$Survived)
r
names(test)
summary(test$Survived)
m.logit <- glm(Survived~Pclass+Sex+Age+SibSp+Fare+family.no+any.lived, family=binomial(logit), data=train.1)
p.logit <- predict(m.logit, type = "response", newdata = train.2)
r <- confusionMatrix(round(p.logit, 0), train.2$Survived)
r
m.logit <- glm(Survived~Pclass+Sex+Age+SibSp+Fare+family.no+any.lived, family=binomial(logit), data=train)
m.logit
m.logit <- glm(Survived~Pclass+Sex+Age+SibSp+Fare+family.no+any.lived, family=binomial(logit), data=train.1)
m.logit <- glm(Survived~Pclass+Sex+Age+SibSp+Fare+family.no+any.lived, family=binomial(logit), data=train)
summary(train)
test$Survived <- predict(m.logit, newdata = test) # Trying a single cf model
summary(test$Survived
)
test$Survived <- predict(m.logit, type = "response", newdata = test) # Trying a single cf model
summary(test$Survived)
test$Survived <- round(predict(m.logit, type = "response", newdata = test),0) # Trying a single cf model
summary(test$Survived)
summary(as.factor(test$Survived))
